{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *ETL realizado sobre los datos de Google*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comenzamos con el dataset de las reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***importamos librerias a utilizar***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extraemos los datos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifica la ruta de la carpeta donde están los archivos JSON\n",
    "folder_path = r'C:\\Users\\Usuario\\Desktop\\HENRY\\PROYECTO FINAL\\Proyecto Final\\datasets\\Google Maps\\review-estados\\review-California'\n",
    "\n",
    "# Obtiene los todos los archivos de la carpeta\n",
    "files = os.listdir(folder_path)\n",
    "dataframes = []\n",
    "\n",
    "# Leer cada archivo JSON línea por línea\n",
    "for file_name in files:\n",
    "    if file_name.endswith('.json'):  # Asegurarse de que solo se lean los archivos JSON\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            df = pd.read_json(file_path, lines=True)  # Leer el archivo JSON línea por línea\n",
    "            dataframes.append(df)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error leyendo {file_name}: {e}\")\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_reviews_g = pd.concat(dataframes, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Visualizamos la cantidad de registros de este Dataset***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reviews_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Transformaciones iniciales determinadas por el EDA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'pics' ya que no la necesitamos para este analisis\n",
    "df_reviews_g.drop(columns=['pics'], inplace=True)\n",
    "\n",
    "# Convertir los diccionarios en la columna 'resp' a cadenas de texto\n",
    "df_reviews_g['resp'] = df_reviews_g['resp'].apply(lambda x: str(x) if isinstance(x, dict) else x)\n",
    "\n",
    "# Convertir la columna 'time' a formato de fecha\n",
    "df_reviews_g['time'] = pd.to_datetime(df_reviews_g['time'], unit='ms')\n",
    "\n",
    "# Eliminar duplicados\n",
    "df_reviews_g.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En un analisis de primera instancia, determinamos tambien, que la funcionalidad de hacer una reseña en un local existente en Google Maps se agrego en el año 2007. Por lo tanto todas las reseñas previas a este año las consideramos erroneas y son descartadas.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarse de que la columna 'time' esté en formato datetime\n",
    "df_reviews_g['time'] = pd.to_datetime(df_reviews_g['time'], errors='coerce')\n",
    "\n",
    "# Detectar outliers en 'time' (fechas fuera del rango)\n",
    "min_date = pd.to_datetime('2007-06-01')\n",
    "max_date = pd.to_datetime('today')\n",
    "\n",
    "# Filtrar las filas que tienen fechas fuera de este rango\n",
    "outliers_time = df_reviews_g[(df_reviews_g['time'] < min_date) | (df_reviews_g['time'] > max_date)]\n",
    "\n",
    "# Eliminamos estos outliers\n",
    "df_reviews_g = df_reviews_g[(df_reviews_g['time'] >= min_date) & (df_reviews_g['time'] <= max_date)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Eliminamos la columna 'resp' ya que no la necesitamos para este analisis***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_g = df_reviews_g.drop(columns=['resp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Reemplazamos valores nulos en la columna 'review_text' con 'Sin Reseña'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13908\\1590490907.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_reviews_g['text'].fillna('Sin Reseña', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_reviews_g['text'].fillna('Sin Reseña', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Luego de estas transformaciones, revisamos nuevamente la cantidad de registros***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624574"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_reviews_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasamos al dataset sobre los Metadatos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***importamos librerias a utilizar***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extraemos los datos***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo .pkl\n",
    "folder_path = r'C:\\Users\\Usuario\\Desktop\\HENRY\\PROYECTO FINAL\\Proyecto Final\\datasets\\Google Maps\\metadata-sitios'\n",
    "\n",
    "# Obtiene los todos los archivos de la carpeta\n",
    "files = os.listdir(folder_path)\n",
    "dataframes = []\n",
    "\n",
    "# Leer cada archivo JSON línea por línea\n",
    "for file_name in files:\n",
    "    if file_name.endswith('.json'):  # Asegurarse de que solo se lean los archivos JSON\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            df = pd.read_json(file_path, lines=True)  # Leer el archivo JSON línea por línea\n",
    "            dataframes.append(df)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error leyendo {file_name}: {e}\")\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_business_google = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verificamos la cantidad de registros***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3025011"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_business_google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Desanidamos Misc***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13908\\2198222021.py:11: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_business_google = df_business_google.applymap(\n"
     ]
    }
   ],
   "source": [
    "# Desanidar la columna 'MISC' que contiene JSON\n",
    "misc_expanded = pd.json_normalize(df_business_google['MISC'])\n",
    "\n",
    "# Combinar las columnas desanidadas con el DataFrame original\n",
    "df_business_google = pd.concat([df_business_google, misc_expanded], axis=1)\n",
    "\n",
    "# Eliminar la columna original 'MISC'\n",
    "df_business_google = df_business_google.drop(columns=['MISC'])\n",
    "\n",
    "# Convertir listas en las nuevas columnas a cadenas separadas por comas\n",
    "df_business_google = df_business_google.applymap(\n",
    "    lambda x: ', '.join(map(str, x)) if isinstance(x, list) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Hacemos transformaciones***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13908\\2017661347.py:14: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_business_google['category'].fillna('Valores Faltantes', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Eliminar las columnas 'price', 'hours' y 'url'\n",
    "df_business_google = df_business_google.drop(columns=['price', 'hours', 'url'])\n",
    "\n",
    "# Eliminar filas duplicadas completamente idénticas\n",
    "df_business_google = df_business_google.drop_duplicates()\n",
    "\n",
    "# Convertir la columna 'state' a tipo texto (string)\n",
    "df_business_google['state'] = df_business_google['state'].astype(str)\n",
    "\n",
    "# Eliminar filas donde 'state' es igual a 'Permanently closed'\n",
    "df_business_google = df_business_google[df_business_google['state'] != 'Permanently closed']\n",
    "\n",
    "# Rellenamos los valores nulos con el texto \"Valores faltantes\"\n",
    "df_business_google['category'].fillna('Valores Faltantes', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verificamos la cantidad de registros luego de los cambios realizados***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2809262"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_business_google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Filtramos para dejar solo los registros con categorias que consideramos dentro de la gastronomia***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_13908\\3655407268.py:5: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df_business_google = df_business_google[df_business_google['category'].str.contains(palabra, case=False, regex=True, na=False)]\n"
     ]
    }
   ],
   "source": [
    "# Definimos palabras clave a buscar luego en las categorias\n",
    "palabra = r'\\b(restaurant|cafe|delivery|diner|bistro|takeout|bar|pub|grill|pizzeria|coffee|bakery|food|eatery|sandwich|snack)\\b'\n",
    "\n",
    "# Filtrar las categorías coincidentes\n",
    "df_business_google = df_business_google[df_business_google['category'].str.contains(palabra, case=False, regex=True, na=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Generamos una columna \"clacificacion\" a partir de la categoria***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificacion = {\n",
    "    'Dining Venue': ['Restaurant'],\n",
    "    'Quick Service': ['Fast food restaurant', 'Pizza restaurant', 'Pizza Takeout'],\n",
    "    'Takeout & Delivery': ['Takeout Restaurant', 'Delivery Restaurant'],\n",
    "    'Mexican Dining': ['Mexican restaurant', 'Taco restaurant'],\n",
    "    'American Dining': ['American restaurant', 'Burger restaurant'],\n",
    "    'Sandwich Bar': ['Sandwich shop'],\n",
    "    'Italian Dining': ['Italian restaurant'],\n",
    "    'Chinese Dining': ['Chinese restaurant'],\n",
    "    'Café & Coffee': ['Coffee shop', 'Cafe'],\n",
    "    'Seafood Dining': ['Seafood restaurant'],\n",
    "    'Barbecue Dining': ['Barbecue restaurant'],\n",
    "    'Asian Fusion': ['Asian restaurant', 'Sushi restaurant', 'Japanese restaurant', 'Thai restaurant'],\n",
    "    'Chicken House': ['Chicken restaurant', 'Chicken wings restaurant'],\n",
    "    'Bakery Shop': ['Bakery', 'Bakery shop'],\n",
    "    'Ice Cream Parlor': ['Ice cream shop'],\n",
    "    'Indian Dining': ['Indian restaurant'],\n",
    "    'Latin American Dining': ['Latin American restaurant'],\n",
    "    'Juice Bar': ['Juice shop'],\n",
    "    'Specialty Catering': ['Caterer'],\n",
    "    'Vegetarian Dining': ['Vegetarian restaurant'],\n",
    "    'Vietnamese Dining': ['Vietnamese Restaurant'],\n",
    "    'Health Foods': ['Health food store', 'Health Food', 'Green Food']\n",
    "}\n",
    "\n",
    "\n",
    "def assign_group(category):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if pd.isna(category):  # Si la categoría es Nula\n",
    "        return 'Other'\n",
    "    for key, values in clasificacion.items():\n",
    "        for value in values:\n",
    "            if value.lower() in category.lower():\n",
    "                return key\n",
    "    return 'Other'\n",
    "\n",
    "df_business_google['clasificacion'] = df_business_google['category'].map(assign_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_business_google = df_business_google[df_business_google['clasificacion'] != 'Other']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtramos los datos mediante el uso de la columna gmap_id (compartida por ambos datasets) para asi dejar tan solo los datos de california en el Dataframe con los datos de los locales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros en df_business_google que coincidan en la columna 'gmap_id'\n",
    "df_business_google = df_business_google[df_business_google['gmap_id'].isin(df_reviews_g['gmap_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Verificamos nuevamente la cantidad de registros para comparar***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7923"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_business_google)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volvemos a transformar el dataset \"Reviews\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir del dataframe df_reviews_g sacamos la columna gmap_id con valores únicos. De esa forma, esa lista permitio filtrar los registros pertenecientes al estado de California en el dataset metadatos de google.\n",
    "Una vez que tenemos aquellos registros definidos, en los que se ha delimitado el dataset al rubro gastronomico y afines, corresponde ahora volver a filtrar este dataset para que solo queden a disposición los registros del estado de california vinculados al sector gastronomico, lo que haremos a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar los registros en df_reviews_g que coincidan en la columna 'gmap_id'\n",
    "df_reviews_google = df_reviews_g[df_reviews_g['gmap_id'].isin(df_business_google['gmap_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>time</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>gmap_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.089912e+20</td>\n",
       "      <td>Song Ro</td>\n",
       "      <td>2021-01-06 05:12:07.056</td>\n",
       "      <td>5</td>\n",
       "      <td>Love there korean rice cake.</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.112903e+20</td>\n",
       "      <td>Rafa Robles</td>\n",
       "      <td>2021-02-09 05:47:28.663</td>\n",
       "      <td>5</td>\n",
       "      <td>Good very good</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.126404e+20</td>\n",
       "      <td>David Han</td>\n",
       "      <td>2020-03-08 05:04:42.296</td>\n",
       "      <td>4</td>\n",
       "      <td>They make Korean traditional food very properly.</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.174403e+20</td>\n",
       "      <td>Anthony Kim</td>\n",
       "      <td>2019-03-07 05:56:56.355</td>\n",
       "      <td>5</td>\n",
       "      <td>Short ribs are very delicious.</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.005808e+20</td>\n",
       "      <td>Mario Marzouk</td>\n",
       "      <td>2017-05-16 05:01:41.933</td>\n",
       "      <td>5</td>\n",
       "      <td>Great food and prices the portions are large</td>\n",
       "      <td>0x80c2c778e3b73d33:0xbdc58662a4a97d49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id           name                    time  rating  \\\n",
       "0  1.089912e+20        Song Ro 2021-01-06 05:12:07.056       5   \n",
       "1  1.112903e+20    Rafa Robles 2021-02-09 05:47:28.663       5   \n",
       "2  1.126404e+20      David Han 2020-03-08 05:04:42.296       4   \n",
       "3  1.174403e+20    Anthony Kim 2019-03-07 05:56:56.355       5   \n",
       "4  1.005808e+20  Mario Marzouk 2017-05-16 05:01:41.933       5   \n",
       "\n",
       "                                               text  \\\n",
       "0                      Love there korean rice cake.   \n",
       "1                                    Good very good   \n",
       "2  They make Korean traditional food very properly.   \n",
       "3                    Short ribs are very delicious.   \n",
       "4      Great food and prices the portions are large   \n",
       "\n",
       "                                 gmap_id  \n",
       "0  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "1  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "2  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "3  0x80c2c778e3b73d33:0xbdc58662a4a97d49  \n",
       "4  0x80c2c778e3b73d33:0xbdc58662a4a97d49  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews_google.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardamos los Dataframes finales en archivos .parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_google.to_parquet(r'C:\\Users\\Usuario\\Desktop\\HENRY\\PROYECTO FINAL\\repo\\epicurean_project\\DATA\\data parcial\\reviews_google.parquet')\n",
    "df_business_google.to_parquet(r'C:\\Users\\Usuario\\Desktop\\HENRY\\PROYECTO FINAL\\repo\\epicurean_project\\DATA\\data parcial\\locales_google.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
